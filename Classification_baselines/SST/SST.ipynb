{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification baseline for Stanford Sentiment Treebank (SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.0 (default, Jun 28 2018, 13:15:42) \n",
      "[GCC 7.2.0]\n",
      "Pytorch: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets \n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "sys.path.insert(0, '../../Utils/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import * \n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SST using Torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix the following error: OSError: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.\n",
    "# Run: \n",
    "# python -m spacy download en\n",
    "\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(tensor_type=torch.LongTensor)\n",
    "\n",
    "train, val, test = datasets.SST.splits(TEXT, LABEL, root='../../Datasets/SST_data', fine_grained=True)\n",
    "\n",
    "\n",
    "TEXT.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\", vectors_cache='../../Datasets/SST_data/vector_cache')\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_itr, val_itr, test_itr = data.BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_key= lambda x: len(x.text), \n",
    "    repeat=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_size = 100\n",
    "hidden_size = 256\n",
    "output_size = 5\n",
    "\n",
    "\n",
    "RNN_model = models.RNN(vocab_size, embedding_size, hidden_size, output_size)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "RNN_model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(RNN_model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "RNN_model = RNN_model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(preds, y):\n",
    "\n",
    "    correct = (preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "\n",
    "    rounded_preds = torch.round(preds)\n",
    "\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        acc = classification_accuracy(predictions.argmax(dim=1), batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = classification_accuracy(predictions.argmax(dim=1), batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljt/cyphercat/venv/lib/python3.7/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train Loss: 1.514, Train Acc: 31.87%, Val. Loss: 1.387, Val. Acc: 39.22%\n",
      "Epoch: 02, Train Loss: 1.368, Train Acc: 39.68%, Val. Loss: 1.362, Val. Acc: 39.36%\n",
      "Epoch: 03, Train Loss: 1.272, Train Acc: 43.81%, Val. Loss: 1.362, Val. Acc: 38.16%\n",
      "Epoch: 04, Train Loss: 1.173, Train Acc: 48.30%, Val. Loss: 1.334, Val. Acc: 39.90%\n",
      "Epoch: 05, Train Loss: 1.073, Train Acc: 53.16%, Val. Loss: 1.417, Val. Acc: 42.22%\n",
      "Epoch: 06, Train Loss: 0.982, Train Acc: 58.08%, Val. Loss: 1.394, Val. Acc: 40.80%\n",
      "Epoch: 07, Train Loss: 0.891, Train Acc: 62.64%, Val. Loss: 1.480, Val. Acc: 41.24%\n",
      "Epoch: 08, Train Loss: 0.805, Train Acc: 67.31%, Val. Loss: 1.611, Val. Acc: 40.03%\n",
      "Epoch: 09, Train Loss: 0.723, Train Acc: 71.15%, Val. Loss: 1.709, Val. Acc: 39.27%\n",
      "Epoch: 10, Train Loss: 0.661, Train Acc: 73.13%, Val. Loss: 1.826, Val. Acc: 40.12%\n",
      "Epoch: 11, Train Loss: 0.606, Train Acc: 75.96%, Val. Loss: 1.836, Val. Acc: 40.61%\n",
      "Epoch: 12, Train Loss: 0.554, Train Acc: 77.66%, Val. Loss: 1.943, Val. Acc: 40.56%\n",
      "Epoch: 13, Train Loss: 0.508, Train Acc: 79.78%, Val. Loss: 2.183, Val. Acc: 37.97%\n",
      "Epoch: 14, Train Loss: 0.466, Train Acc: 81.98%, Val. Loss: 2.082, Val. Acc: 39.58%\n",
      "Epoch: 15, Train Loss: 0.444, Train Acc: 82.72%, Val. Loss: 2.173, Val. Acc: 39.84%\n",
      "Epoch: 16, Train Loss: 0.401, Train Acc: 84.55%, Val. Loss: 2.419, Val. Acc: 39.48%\n",
      "Epoch: 17, Train Loss: 0.372, Train Acc: 85.87%, Val. Loss: 2.403, Val. Acc: 38.91%\n",
      "Epoch: 18, Train Loss: 0.355, Train Acc: 86.61%, Val. Loss: 2.613, Val. Acc: 40.20%\n",
      "Epoch: 19, Train Loss: 0.328, Train Acc: 87.35%, Val. Loss: 2.622, Val. Acc: 39.48%\n",
      "Epoch: 20, Train Loss: 0.305, Train Acc: 88.32%, Val. Loss: 2.826, Val. Acc: 39.26%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(RNN_model, train_itr, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(RNN_model, val_itr, criterion)\n",
    "    \n",
    "    print('Epoch: %02d, Train Loss: %.3f, Train Acc: %.2f%%, Val. Loss: %.3f, Val. Acc: %.2f%%' % (epoch+1, train_loss, train_acc*100, valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN test accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(RNN_model, test_itr, criterion)\n",
    "\n",
    "print('RNN test accuracy: %.2f' % (test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
