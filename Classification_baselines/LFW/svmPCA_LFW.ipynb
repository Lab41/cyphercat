{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "\n",
    "sys.path.append('../../Utils')\n",
    "\n",
    "from SVC_Utils import *\n",
    "from data_downloaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading LFW.\n",
      "LFW successfully downloaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "get_lfw('./data')\n",
    "data_dir = \"./data/lfw/lfw_20/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "\n",
    "for i in os.listdir(data_dir):\n",
    "    for j in os.listdir(os.path.join(data_dir,i)):\n",
    "        images.append(os.path.join(data_dir,i,j))\n",
    "        \n",
    "classes=[]\n",
    "classes_to_idx={}\n",
    "j=0;\n",
    "\n",
    "for i in images:\n",
    "    name=i.split('/')[4];\n",
    "    if name not in classes_to_idx:\n",
    "        classes.append(name)\n",
    "        classes_to_idx[name]=j\n",
    "        j+=1\n",
    "\n",
    "images=np.random.permutation(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418\n",
      "605\n"
     ]
    }
   ],
   "source": [
    "trainset_len=int(.8*(len(images)))\n",
    "train_imgs=images[:trainset_len];\n",
    "test_imgs=images[trainset_len:]\n",
    "print(len(trainset));print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFW(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list, classes_list, transform=None):\n",
    "        self.classes_to_idx=classes_list\n",
    "        self.img_list=img_list\n",
    "        self.transform=transform;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list);\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=self.img_list[idx]\n",
    "        sample=io.imread(img)\n",
    "        label=self.classes_to_idx[img.split('/')[4]]\n",
    "        if self.transform is not None:\n",
    "            sample=self.transform(sample)\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.ToTensor()\n",
    "\n",
    "trainset=LFW(train_imgs,classes_to_idx,transform=transform)\n",
    "testset=LFW(test_imgs,classes_to_idx,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainset.__len__(), shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=testset.__len__(), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininputs, traintargets=load(trainset)\n",
    "testinputs, testtargets=load(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=180\n",
    "C_range = np.logspace(-1,1,3) #[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02]\n",
    "gamma_range = np.logspace(-2, 0, 3) #[1.e-03 1.e-02 1.e-01 1.e+00 1.e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs=hp_grid(n_components=n_components, C_range=C_range, gamma_range=gamma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_clfs=train_grid(clfs, traininputs, traintargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores training and testing accuracies in matrices (Rows: C_range, Cols: gamma_range)\n",
    "\n",
    "train_accs=np.random.randn(len(C_range),len(gamma_range))\n",
    "test_accs=np.random.randn(len(C_range),len(gamma_range))\n",
    "test_preds=[]\n",
    "k=0;\n",
    "\n",
    "for i in range(len(C_range)):\n",
    "    for j in range(len(gamma_range)):\n",
    "        train_accs[i,j]=predict_eval(fitted_clfs[k], traininputs, traintargets, training=True)[1]\n",
    "        preds, test_accs[i,j]=predict_eval(fitted_clfs[k], testinputs, testtargets)\n",
    "        test_preds.append(preds)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=['C = 1','C = 10']\n",
    "cols=['gamma = .01','gamma = .1']\n",
    "\n",
    "trainacc_df=pd.DataFrame(data=train_accs, index=idx, columns=cols)\n",
    "testacc_df=pd.DataFrame(data=test_accs, index=idx, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training accuracy for C/gamma grid\n",
    "trainacc_df.style.background_gradient(cmap='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy for C/gamma grid\n",
    "testacc_df.style.background_gradient(cmap='GnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxacc, gen=maxacc_gen(test_accs, train_accs, clfs)\n",
    "\n",
    "fn_max_acc = 'SVMCIFAR10_maxacc_proba.pkl'\n",
    "fn_gen = 'SVMCIFAR10_gen_proba.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_proba(fn_max_acc, maxacc, traininputs, traintargets)\n",
    "save_proba(fn_gen, gen, traininputs, traintargets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
