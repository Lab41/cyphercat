{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.5 (default, Jul  6 2018, 19:12:46) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pytorch: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, '../../../Utils/')\n",
    "sys.path.insert(0, '../../../')\n",
    "import cyphercat as cc\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import * \n",
    "from SVC_Utils import *\n",
    "\n",
    "#audio\n",
    "import librosa as libr\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "k = 3\n",
    "\n",
    "pretrained = True #run this with networks that have already been trained\n",
    "\n",
    "transform_type = 'SFTF' #either STFT or MFCC  \n",
    "\n",
    "data = 'VOiCES' #'Libri' or 'VOiCES'\n",
    "defense = 'dimen_reduc_top3_breakpost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Speech preprocessing\n",
    "\n",
    "class tensorToMFCC:\n",
    "    def __call__(self, y):\n",
    "#         y = y.numpy()\n",
    "        dims = y.shape\n",
    "        y = libr.feature.melspectrogram(np.reshape(y, (dims[1],)), 16000, n_mels=number_of_mels,\n",
    "                               fmax=8000)\n",
    "        y = libr.feature.mfcc(S = libr.power_to_db(y))\n",
    "        y = torch.from_numpy(y)                           \n",
    "        return y.float()\n",
    "\n",
    "class STFT:\n",
    "    def __call__(self,y):\n",
    "        dims = y.shape\n",
    "        y = np.abs(libr.core.stft(np.reshape(y, (dims[1],))))\n",
    "        y = torch.from_numpy(y).permute(1,0)\n",
    "        return y.float()\n",
    "\n",
    "if transform_type == 'SFTF':\n",
    "    target_net_type = cc.ft_cnn_classifer\n",
    "    shadow_net_type = cc.ft_cnn_classifer\n",
    "    in_size = 94# 20 forMFCC,  94 for STFT\n",
    "    transform  = STFT() ## STFT or MFCC\n",
    "elif transform_type == 'MFCC':\n",
    "    transform  = tensorToMFCC()\n",
    "    target_net_type = cc.MFCC_cnn_classifier\n",
    "    shadow_net_type = cc.MFCC_cnn_classifier\n",
    "    in_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seconds = 3\n",
    "n_epochs = 50\n",
    "shadow_epochs = 15\n",
    "n_epochs_attack = 100\n",
    "sampling_rate = 16000\n",
    "number_of_mels =128\n",
    "lr = 0.001\n",
    "\n",
    "# attacking means data for a target & shadow network.\n",
    "# This will also split \"out data\" from totally different speakers -- data none of the \n",
    "# other networks have seen, for training & testing the attack network. This will be\n",
    "# an equivalent amount of data to the train split as defined about\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(0, './../../../Utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load audio data: VOiCES or LibriSpeech, & Split into valid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading splits\n",
      "Initialising VOiCESDataset with minimum length = 3s and subset = room-1\n",
      "\t Finished indexing room-1. 187260 usable files found.\n",
      "Build/load speaker membership inference splits\n",
      "Found default speaker splits, loading dataframe\n",
      "Build/load sample membership inference splits\n",
      "Found default sample splits, loading dataframe\n",
      "\n",
      " ------- Speaker split statistics ------- \n",
      "\t\t ---- Split 0 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 69\t\t 37344\n",
      "Female:\t\t 69\t\t 34992\n",
      "Total:\t\t 138\t\t 72336\n",
      "\t\t ---- Split 1 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 69\t\t 8064\n",
      "Female:\t\t 69\t\t 7248\n",
      "Total:\t\t 138\t\t 15312\n",
      "\t\t ---- Split 2 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 34\t\t 20832\n",
      "Female:\t\t 34\t\t 20652\n",
      "Total:\t\t 68\t\t 41484\n",
      "\t\t ---- Split 3 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 35\t\t 21888\n",
      "Female:\t\t 35\t\t 21408\n",
      "Total:\t\t 70\t\t 43296\n",
      "\t\t ---- Split 4 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 16\t\t 8064\n",
      "Female:\t\t 15\t\t 7248\n",
      "Total:\t\t 31\t\t 15312\n",
      "\t\t ---- Split 5 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 12\t\t 7728\n",
      "Female:\t\t 12\t\t 7104\n",
      "Total:\t\t 24\t\t 14832\n",
      " ---------------------------------------- \n",
      "\n",
      " ------- Sample split statistics -------- \n",
      "\t\t ---- Split 0 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 75\t\t 40560\n",
      "Female:\t\t 75\t\t 37980\n",
      "Total:\t\t 150\t\t 78540\n",
      "\t\t ---- Split 1 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 75\t\t 8880\n",
      "Female:\t\t 75\t\t 7824\n",
      "Total:\t\t 150\t\t 16704\n",
      "\t\t ---- Split 2 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 75\t\t 24528\n",
      "Female:\t\t 75\t\t 24480\n",
      "Total:\t\t 150\t\t 49008\n",
      "\t\t ---- Split 3 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 75\t\t 21888\n",
      "Female:\t\t 75\t\t 21120\n",
      "Total:\t\t 150\t\t 43008\n",
      "\t\t ---- Split 4 ---- \n",
      "\tUnique speakers \t Samples\n",
      "Male:\t\t 18\t\t 8880\n",
      "Female:\t\t 16\t\t 7824\n",
      "Total:\t\t 34\t\t 16704\n",
      " ---------------------------------------- \n",
      "\n",
      "Finished splitting data.\n",
      "Initializing dataset\n"
     ]
    }
   ],
   "source": [
    "print('Loading splits')\n",
    "subset = 'room-1'\n",
    "if data == 'Libri':\n",
    "    [dfs, sample_df] = cc.Libri_preload_and_split()\n",
    "    print('Initializing dataset')\n",
    "    valid_sequence_train_target = cc.LibriSpeechDataset(df=dfs[0], transform = transform)\n",
    "    valid_sequence_test_target = cc.LibriSpeechDataset(df=dfs[1], transform = transform)\n",
    "    valid_sequence_train_shadow = cc.LibriSpeechDataset(df=dfs[2], transform = transform)\n",
    "    valid_sequence_test_shadow = cc.LibriSpeechDataset(df=dfs[3], transform = transform)\n",
    "    valid_sequence_attack_in = cc.LibriSpeechDataset(df=dfs[4], transform = transform)\n",
    "    valid_sequence_attack_out = cc.LibriSpeechDataset(df=dfs[5], transform = transform)\n",
    "\n",
    "    print('Succesfully loaded libri-speech')\n",
    "elif data == 'VOiCES':\n",
    "    [dfs, sample_df] = cc.Voices_preload_and_split(subset = subset)\n",
    "    print('Initializing dataset')\n",
    "    valid_sequence_train_target = cc.Voices_dataset(df=dfs[0], transform = transform)\n",
    "    valid_sequence_test_target = cc.Voices_dataset(df=dfs[1], transform = transform)\n",
    "    valid_sequence_train_shadow = cc.Voices_dataset(df=dfs[2], transform = transform)\n",
    "    valid_sequence_test_shadow = cc.Voices_dataset(df=dfs[3], transform = transform)\n",
    "    valid_sequence_attack_in = cc.Voices_dataset(df=dfs[4], transform = transform)\n",
    "    valid_sequence_attack_out = cc.Voices_dataset(df=dfs[5], transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # to look at the index file:\n",
    "\n",
    "# # #look at splits file for reference\n",
    "# dff = pd.read_csv(os.getcwd()+'/../../../Datasets/splits/libri-train-clean-100/libri_4.csv')\n",
    "# print(dff.head())\n",
    "# dff2 = pd.read_csv(os.getcwd()+'/../../../Datasets/splits/VOiCES-room-1/VOiCES_0.csv')\n",
    "# print(dff2.head())\n",
    "\n",
    "\n",
    "# # df = pd.read_csv(os.getcwd()+'/../../../Datasets/VOiCES-room-1.index.csv')\n",
    "# # df.head()\n",
    "\n",
    "# # g = df.groupby(['id','Section']).groups\n",
    "\n",
    "# # dfn = pd.DataFrame(columns = ['id','Section'])\n",
    "# # idx = 0\n",
    "# # for key in g.keys():\n",
    "# #     dfn.at[idx,'id']=key[0]\n",
    "# #     dfn.at[idx,'Section']=key[1]\n",
    "# #     idx +=1\n",
    "\n",
    "# # print(len(np.unique(df.id)), 'speakers')\n",
    "# # print(len(df), 'files')\n",
    "# # print(dfn.groupby('id').count().min()[0], 'tracks min')\n",
    "# # print(dfn.groupby('id').count().max()[0], 'tracks max')\n",
    "# # print(dfn.groupby('id').count().mean()[0], 'tracks mean')\n",
    "\n",
    "# # print('min speaker minutes',df.groupby('id').mean()['speaker_minutes'].min())\n",
    "# # print('max speaker minutes',df.groupby('id').mean()['speaker_minutes'].max())\n",
    "# # print('mean speaker minutes',df.groupby('id').mean()['speaker_minutes'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = [.2,.8]\n",
    "# df1 = pd.DataFrame(columns = df.columns)\n",
    "# df2 = pd.DataFrame(columns = df.columns)\n",
    "# # For each speaker, identify unique segments: \n",
    "# for spkr_id in df.id.unique():\n",
    "#     mini_df = df[df['id'] == spkr_id]\n",
    "#     # Identify segments:\n",
    "#     n_seg = len(mini_df.Section.unique())\n",
    "#     seg1 = round(splits[0]*n_seg)\n",
    "#     # Segments are not ordered in a particular way, so just pick the first few for seg1\n",
    "#     seg1s = mini_df.Section.unique()[:seg1]\n",
    "#     df1 = df1.append(mini_df[mini_df['Section'].isin(seg1s)])\n",
    "#     df2 = df2.append(mini_df[~mini_df['Section'].isin(seg1s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Loaders for data for target model & shadow model \n",
    "target_train_loader = DataLoader(valid_sequence_train_target,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8,\n",
    "                    drop_last = True\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "target_test_loader = DataLoader(valid_sequence_test_target,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "shadow_train_loader = DataLoader(valid_sequence_train_shadow,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8,\n",
    "                    drop_last = True\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "shadow_test_loader = DataLoader(valid_sequence_test_shadow,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "test_loader_in = DataLoader(valid_sequence_attack_in,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "\n",
    "\n",
    "test_loader_out = DataLoader(valid_sequence_attack_out,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=8\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table with summary\n",
    "\n",
    "summary_file = 'summary.pkl'\n",
    "columns = ['Data','Transform','Training epochs', '# speakers','Train accuracy', 'Test accuracy', \n",
    "           'Attack type', 'Defense','Attack Accuracy', 'Attack Precision','Attack Recall', 'Thresholds']\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "df_idx = len(df)\n",
    "\n",
    "#set a bunch of known values\n",
    "df.at[df_idx,'Transform'] =transform_type\n",
    "df.at[df_idx,'Training epochs'] = n_epochs\n",
    "df.at[df_idx,'Attack type'] = 1\n",
    "df.at[df_idx,'Defense'] = defense\n",
    "df.at[df_idx,'Data'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Targets\n",
    "The model being attacked; if network, architecture can differ from that of shadow network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138  speakers\n"
     ]
    }
   ],
   "source": [
    "#Initialize NN\n",
    "\n",
    "#in_size defined above\n",
    "n_hidden = 512\n",
    "n_classes = valid_sequence_test_target.num_speakers\n",
    "print(n_classes,' speakers')\n",
    "df.at[df_idx,'# speakers']=n_classes\n",
    "\n",
    "\n",
    "target_net = target_net_type(n_classes).to(device)\n",
    "target_net.apply(models.weights_init)\n",
    "\n",
    "target_loss = nn.CrossEntropyLoss()\n",
    "target_optim = optim.Adam(target_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_weights/CNN_voice_classifierVOiCES_target_SFTF49.pth.tar\n",
      "Succesfully loaded checkpoint \n",
      "Dataset: VOiCES \n",
      "Epoch: 49 \n",
      "Loss: None           \n",
      "Accuracy: [98.585453539823, 77.76907001044933]\n"
     ]
    }
   ],
   "source": [
    "#file name for this set of hyperparameters\n",
    "fn = 'model_weights/CNN_voice_classifier'+data+'_target_'+transform_type+str(n_epochs-1)\n",
    "\n",
    "#Train NN\n",
    "if not pretrained:\n",
    "    train_accuracy, test_accuracy = cc.train(target_net, target_train_loader, target_test_loader, target_optim, target_loss, n_epochs, verbose = False) \n",
    "    df.at[df_idx,'Train accuracy'] =round(train_accuracy,4)/100\n",
    "    df.at[df_idx,'Test accuracy'] = round(test_accuracy,4)/100\n",
    "    cc.save_checkpoint(model = target_net, optimizer = target_optim,\n",
    "                           epoch = n_epochs-1, data_descriptor = data, \n",
    "                           accuracy = [train_accuracy, test_accuracy],\n",
    "                           filename = fn)\n",
    "    \n",
    "else:\n",
    "    fn = fn + '.pth.tar'\n",
    "    print(fn)\n",
    "    cc.load_checkpoint(model = target_net, checkpoint = fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize/Train Shadow Model\n",
    "Shadow model mimics the target network, emulating the target model's differences in prediction probabilities for samples in and out of its dataset. For this attack, only one shadow model is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sequence_train_shadow.num_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimen_reduc_top3_breakpost\n"
     ]
    }
   ],
   "source": [
    "# IF defending:\n",
    "if defense == 'dimen_reduc_top3_breakpost':\n",
    "    print(defense)\n",
    "    target_net = cc.defenses.dimensionality_reduction(model = target_net, n_top = 3, break_posterior = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n shadow speakers 70\n"
     ]
    }
   ],
   "source": [
    "#Initialize models\n",
    "\n",
    "n_classes = valid_sequence_test_shadow.num_speakers\n",
    "print('n shadow speakers',n_classes)\n",
    "\n",
    "#NN\n",
    "shadow_net = shadow_net_type(n_classes).to(device)\n",
    "shadow_net.apply(models.weights_init)\n",
    "\n",
    "shadow_loss = nn.CrossEntropyLoss()\n",
    "shadow_optim = optim.Adam(shadow_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Attack Model\n",
    "A binary classifier to determine membership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Training shadow network ----\n",
      "[0/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 83.42 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 4.07 %%\n",
      "\n",
      "\n",
      "[1/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 91.24 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.35 %%\n",
      "\n",
      "\n",
      "[2/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 92.84 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.41 %%\n",
      "\n",
      "\n",
      "[3/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 94.29 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.98 %%\n",
      "\n",
      "\n",
      "[4/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 94.65 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.97 %%\n",
      "\n",
      "\n",
      "[5/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.76 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.21 %%\n",
      "\n",
      "\n",
      "[6/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 95.55 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.41 %%\n",
      "\n",
      "\n",
      "[7/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 96.19 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.93 %%\n",
      "\n",
      "\n",
      "[8/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.17 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.51 %%\n",
      "\n",
      "\n",
      "[9/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.55 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.20 %%\n",
      "\n",
      "\n",
      "[10/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.83 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.62 %%\n",
      "\n",
      "\n",
      "[11/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 97.93 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.78 %%\n",
      "\n",
      "\n",
      "[12/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.38 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 3.17 %%\n",
      "\n",
      "\n",
      "[13/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.01 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.87 %%\n",
      "\n",
      "\n",
      "[14/15]\n",
      "Training:\n",
      "\n",
      "Accuracy = 98.40 %%\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "Accuracy = 2.68 %%\n",
      "\n",
      "\n",
      "---- Training attack network ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f7f41404048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/reduction.py\", line 153, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f7f41404dd8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/reduction.py\", line 153, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f7f41404eb8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Evaluate attack ----\n"
     ]
    }
   ],
   "source": [
    "# Attack the network: \n",
    "\n",
    "attack_net_nn = models.mlleaks_mlp(n_in=k).to(device)\n",
    "attack_loss = nn.BCEWithLogitsLoss()\n",
    "attack_optim_nn= optim.Adam(attack_net_nn.parameters(), lr=lr)\n",
    "\n",
    "df_pr = cc.ml_leaks1(target=target_net, shadow_model = shadow_net, attacker_model = attack_net_nn,\n",
    "            target_in_loader = test_loader_in, target_out_loader = test_loader_out,\n",
    "            shadow_train_loader = shadow_train_loader, shadow_out_loader=shadow_test_loader,\n",
    "            shadow_optim = shadow_optim, attack_optim = attack_optim_nn, \n",
    "            shadow_criterion = shadow_loss, attack_criterion = attack_loss, \n",
    "            shadow_epochs = shadow_epochs, attack_epochs = n_epochs_attack, retrain = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'model_weights/CNN_voice_classifier'+data+'_attack_'+transform_type+str(n_epochs_attack-1)\n",
    "cc.save_checkpoint(model = attack_net_nn, optimizer = attack_optim_nn,\n",
    "                               epoch = n_epochs_attack, data_descriptor = data, \n",
    "                               filename = fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.525</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.530</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.535</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.540</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.545</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.550</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.555</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.560</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.565</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.570</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.575</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.580</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.585</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.590</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.595</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.605</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.610</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.615</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.620</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.625</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.630</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.635</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.640</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.645</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.850</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.855</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.860</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.865</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.870</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.875</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.880</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.885</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.890</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.895</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.900</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.905</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.910</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.915</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.920</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.930</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.935</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.940</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.945</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.950</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.955</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.960</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.965</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.970</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.975</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.980</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.985</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.990</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.995</td>\n",
       "      <td>49.973046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Thresholds   Accuracy  Precision  Recall\n",
       "0        0.500  49.973046        0.0     0.0\n",
       "1        0.505  49.973046        0.0     0.0\n",
       "2        0.510  49.973046        0.0     0.0\n",
       "3        0.515  49.973046        0.0     0.0\n",
       "4        0.520  49.973046        0.0     0.0\n",
       "5        0.525  49.973046        0.0     0.0\n",
       "6        0.530  49.973046        0.0     0.0\n",
       "7        0.535  49.973046        0.0     0.0\n",
       "8        0.540  49.973046        0.0     0.0\n",
       "9        0.545  49.973046        0.0     0.0\n",
       "10       0.550  49.973046        0.0     0.0\n",
       "11       0.555  49.973046        0.0     0.0\n",
       "12       0.560  49.973046        0.0     0.0\n",
       "13       0.565  49.973046        0.0     0.0\n",
       "14       0.570  49.973046        0.0     0.0\n",
       "15       0.575  49.973046        0.0     0.0\n",
       "16       0.580  49.973046        0.0     0.0\n",
       "17       0.585  49.973046        0.0     0.0\n",
       "18       0.590  49.973046        0.0     0.0\n",
       "19       0.595  49.973046        0.0     0.0\n",
       "20       0.600  49.973046        0.0     0.0\n",
       "21       0.605  49.973046        0.0     0.0\n",
       "22       0.610  49.973046        0.0     0.0\n",
       "23       0.615  49.973046        0.0     0.0\n",
       "24       0.620  49.973046        0.0     0.0\n",
       "25       0.625  49.973046        0.0     0.0\n",
       "26       0.630  49.973046        0.0     0.0\n",
       "27       0.635  49.973046        0.0     0.0\n",
       "28       0.640  49.973046        0.0     0.0\n",
       "29       0.645  49.973046        0.0     0.0\n",
       "..         ...        ...        ...     ...\n",
       "70       0.850  49.973046        0.0     0.0\n",
       "71       0.855  49.973046        0.0     0.0\n",
       "72       0.860  49.973046        0.0     0.0\n",
       "73       0.865  49.973046        0.0     0.0\n",
       "74       0.870  49.973046        0.0     0.0\n",
       "75       0.875  49.973046        0.0     0.0\n",
       "76       0.880  49.973046        0.0     0.0\n",
       "77       0.885  49.973046        0.0     0.0\n",
       "78       0.890  49.973046        0.0     0.0\n",
       "79       0.895  49.973046        0.0     0.0\n",
       "80       0.900  49.973046        0.0     0.0\n",
       "81       0.905  49.973046        0.0     0.0\n",
       "82       0.910  49.973046        0.0     0.0\n",
       "83       0.915  49.973046        0.0     0.0\n",
       "84       0.920  49.973046        0.0     0.0\n",
       "85       0.925  49.973046        0.0     0.0\n",
       "86       0.930  49.973046        0.0     0.0\n",
       "87       0.935  49.973046        0.0     0.0\n",
       "88       0.940  49.973046        0.0     0.0\n",
       "89       0.945  49.973046        0.0     0.0\n",
       "90       0.950  49.973046        0.0     0.0\n",
       "91       0.955  49.973046        0.0     0.0\n",
       "92       0.960  49.973046        0.0     0.0\n",
       "93       0.965  49.973046        0.0     0.0\n",
       "94       0.970  49.973046        0.0     0.0\n",
       "95       0.975  49.973046        0.0     0.0\n",
       "96       0.980  49.973046        0.0     0.0\n",
       "97       0.985  49.973046        0.0     0.0\n",
       "98       0.990  49.973046        0.0     0.0\n",
       "99       0.995  49.973046        0.0     0.0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ascertain best results\n",
    "\n",
    "df.at[df_idx,'Attack Precision'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Precision.values[0],4)\n",
    "df.at[df_idx,'Attack Recall'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Recall.values[0],4)\n",
    "df.at[df_idx,'Attack Accuracy'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Accuracy.values[0],4)/100\n",
    "df.at[df_idx,'Threshold'] = round(df_pr[df_pr['Accuracy']==df_pr['Accuracy'].max()].Thresholds.values[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading summary file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# Add results to table\n",
    "\n",
    "try:\n",
    "    df_summ = pd.read_pickle(summary_file)\n",
    "    print('Loading summary file')\n",
    "\n",
    "except:\n",
    "    print('Creating new summary file')\n",
    "\n",
    "# Append row you created\n",
    "df_summ = df_summ.append(df) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated df\n",
    "df_summ.to_pickle(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># speakers</th>\n",
       "      <th>Attack Accuracy</th>\n",
       "      <th>Attack Precision</th>\n",
       "      <th>Attack Recall</th>\n",
       "      <th>Attack type</th>\n",
       "      <th>Data</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Training epochs</th>\n",
       "      <th>Transform</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.878611</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Libri</td>\n",
       "      <td>None</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>0.995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SFTF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.49832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Libri</td>\n",
       "      <td>dimen_reduc_top3_breakpost</td>\n",
       "      <td>0.94333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992165</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SFTF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138.0</td>\n",
       "      <td>0.827695</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VOiCES</td>\n",
       "      <td>None</td>\n",
       "      <td>0.777691</td>\n",
       "      <td>0.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985855</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SFTF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.0</td>\n",
       "      <td>0.49973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VOiCES</td>\n",
       "      <td>dimen_reduc_top3_breakpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SFTF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # speakers Attack Accuracy Attack Precision Attack Recall  Attack type  \\\n",
       "0       125.0        0.878611           0.8585        0.9076          1.0   \n",
       "1       125.0         0.49832                0             0          1.0   \n",
       "2       138.0        0.827695           0.7829        0.9072          1.0   \n",
       "0       138.0         0.49973                0             0          1.0   \n",
       "\n",
       "     Data                     Defense Test accuracy  Threshold Thresholds  \\\n",
       "0   Libri                        None      0.949666      0.995        NaN   \n",
       "1   Libri  dimen_reduc_top3_breakpost       0.94333      0.500        NaN   \n",
       "2  VOiCES                        None      0.777691      0.990        NaN   \n",
       "0  VOiCES  dimen_reduc_top3_breakpost           NaN      0.500        NaN   \n",
       "\n",
       "  Train accuracy  Training epochs Transform  index  \n",
       "0       0.995227             50.0      SFTF    NaN  \n",
       "1       0.992165             50.0      SFTF    NaN  \n",
       "2       0.985855             50.0      SFTF    NaN  \n",
       "0            NaN             50.0      SFTF    NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Attack Nets\n",
    "How well the trained attack models classify a sample as in or out of a target model's training dataset, and how performance is affected by target hyperparameters and which models attack which targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summ = pd.read_pickle(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table(df):\n",
    "    df['# speakers'] =df['# speakers'].astype(float)\n",
    "    df['Training epochs'] =df['Training epochs'].astype(float)\n",
    "    df['Attack type'] =df['Attack type'].astype(float)\n",
    "\n",
    "    #style table\n",
    "    import seaborn as sns\n",
    "\n",
    "    cg = sns.light_palette(\"green\", as_cmap=True)\n",
    "    cm = sns.light_palette(\"magenta\", as_cmap=True)\n",
    "    bl = sns.light_palette(\"blue\", as_cmap=True)\n",
    "    orr = sns.light_palette(\"orange\", as_cmap=True)\n",
    "    gr = sns.light_palette(\"gray\", as_cmap=True)\n",
    "\n",
    "    # df.style.bar(subset=['Train accuracy', 'Test accuracy'], align='mid', color=['#d65f5f', '#5fba7d'])\n",
    "    s = df.style.\\\n",
    "        format({\"Attack Precision\": \"{:.2%}\",\"Attack Recall\": \"{:.2%}\",\"Attack Accuracy\": \"{:.2%}\"}).\\\n",
    "        format({\"Train accuracy\": \"{:.2%}\",\"Test accuracy\": \"{:.2%}\"}).\\\n",
    "        hide_index().\\\n",
    "        set_properties(**{'font-size': \"16pt\",'column-size':\"24pt\",'width': '100px'})\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "style is not supported for non-unique indicies.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-16673cd04702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_summ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-adf4ea8d83cc>\u001b[0m in \u001b[0;36mshow_table\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# df.style.bar(subset=['Train accuracy', 'Test accuracy'], align='mid', color=['#d65f5f', '#5fba7d'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m        \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Attack Precision\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.2%}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Attack Recall\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.2%}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Attack Accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.2%}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m        \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Train accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.2%}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Test accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"{:.2%}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m        \u001b[0mhide_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m        \u001b[0mset_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'font-size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"16pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'column-size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"24pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'100px'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mstyle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \"\"\"\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStyler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, precision, table_styles, uuid, caption, table_attributes)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"style is not supported for non-unique indicies.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: style is not supported for non-unique indicies."
     ]
    }
   ],
   "source": [
    "s = show_table(df_summ)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    background_gradient(cmap=cg,subset=['Train accuracy', 'Test accuracy']).\\\n",
    "    background_gradient(cmap=bl,subset=['Precision', 'Recall']).\\\n",
    "    background_gradient(cmap=orr,subset=['Training epochs']).\\\n",
    "    background_gradient(cmap=gr,subset=['Attack type']).\\\n",
    "    background_gradient(cmap=cm,subset=['# speakers']).\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
